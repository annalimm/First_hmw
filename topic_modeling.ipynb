{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=ENGLISH_STOP_WORDS,\n",
    "                             analyzer='word', binary=True, min_df=10, max_df=1.0)\n",
    "vectorizer.fit(newsgroups_train.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 10441)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запускаем модель LDA и Gibbs Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def lda(X, tags_n, alpha, beta, iter_):\n",
    "    n_kw = np.zeros((tags_n, X.shape[1]))\n",
    "    n_dk = np.zeros((X.shape[0], tags_n))\n",
    "    n_k = np.zeros(tags_n)\n",
    "    d, w = X.nonzero()\n",
    "    docs, words = X.nonzero()\n",
    "    z = np.random.choice(tags_n, docs.shape[0])\n",
    "    # assign random tags\n",
    "    for d, w, z_ in zip(docs, words, z):\n",
    "        n_dk[d, z_] += 1\n",
    "        n_kw[z_, w] += 1\n",
    "        n_k[z_] += 1\n",
    "    # run the algo\n",
    "    for it in range(iter_):\n",
    "        for idx, d in enumerate(docs):\n",
    "            w = words[idx]\n",
    "            t = z[idx]\n",
    "            n_dk[d, t] -= 1\n",
    "            n_kw[t, w] -= 1\n",
    "            n_k[t] -= 1\n",
    "            p = (n_dk[d, :] + alpha)*(n_kw[:, w] + beta[w])/(n_k + beta.sum())\n",
    "            z[idx] = np.random.choice(np.arange(tags_n), p=p/p.sum())\n",
    "            n_dk[d, z[idx]] += 1\n",
    "            n_kw[z[idx], w] += 1\n",
    "            n_k[z[idx]] += 1\n",
    "    return z, n_kw, n_dk, n_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_n = 20\n",
    "start = time.time()\n",
    "z, n_kw, n_dk, n_k = lda(X_train, \n",
    "                         tags_n, \n",
    "                         alpha=np.ones(tags_n), \n",
    "                         beta=np.ones(X_train.shape[1]), \n",
    "                         iter_=50)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:28.0 min 34.0 s\n"
     ]
    }
   ],
   "source": [
    "print(f'Time:{np.round((end - start)/60, 0)} min {np.mod(np.round(end - start, 0),60)} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выведем топ 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = np.argsort(n_kw, axis=1)[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:\n",
      "0- 10, 1993, date, edu, following, information, internet, mail, research, university;\n",
      "1- actually, did, doesn, doing, heard, let, maybe, sure, tell, understand;\n",
      "2- agree, believe, case, doesn, fact, mean, point, reason, things, true;\n",
      "3- ago, believe, com, day, did, edu, ll, long, quite, read;\n",
      "4- card, disk, drive, edu, hard, mac, monitor, offer, sale, video;\n",
      "5- believe, bible, christ, christian, christians, god, jesus, life, man, religion;\n",
      "6- children, country, government, israel, killed, rights, said, state, war, world;\n",
      "7- bike, buy, car, cars, drive, engine, looking, miles, road, speed;\n",
      "8- 10, game, games, league, play, players, season, team, win, year;\n",
      "9- 14, ah, end, ll, ma, max, mi, mr, ms, tm;\n",
      "10- advance, appreciated, help, hi, mail, problem, running, using, windows, work;\n",
      "11- american, clinton, government, house, national, president, public, states, support, white;\n",
      "12- article, com, edu, heard, interested, mail, news, post, really, stuff;\n",
      "13- available, code, file, ftp, program, server, user, using, version, window;\n",
      "14- chip, clipper, encryption, government, key, keys, law, legal, phone, public;\n",
      "15- actually, circuit, current, difference, goes, heat, hot, line, lot, power;\n",
      "16- cause, earth, high, large, long, low, small, space, work, years;\n",
      "17- ago, bit, case, didn, ll, post, quite, reading, remember, yes;\n",
      "18- actually, area, doesn, high, idea, lot, probably, thing, true, yes;\n",
      "19- better, did, didn, going, got, let, ll, really, thing, years;\n",
      "\n",
      " targets: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print('Topics:')\n",
    "for idx, t in enumerate(top_10):\n",
    "    d = np.zeros((1, X_train.shape[1]))\n",
    "    for w in t:\n",
    "        d[0, w] = 1\n",
    "    topic = ', '.join(vectorizer.inverse_transform(d)[0])\n",
    "    print(f'{idx}- {topic};')\n",
    "print(f'\\n targets: {newsgroups_train.target_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди полученных тем можно разобрать такие как:\n",
    "4. mac hardware\n",
    "5. religion\n",
    "6. politics\n",
    "7. autos\n",
    "8. sport\n",
    "9. os ms-windows\n",
    "10. os windows\n",
    "11. politics\n",
    "13. windows x\n",
    "14. cryptography\n",
    "15. pc hardware "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
